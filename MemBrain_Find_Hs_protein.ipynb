{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a35a667-d2bb-438b-bcb8-1be1a1523f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from my_utils import get_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc780fb-b667-4095-94c0-53d749df53d7",
   "metadata": {},
   "source": [
    "# Step 1: Get protein information for MemBrain raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b90fa3-d089-4b62-a7ae-d072c3f16aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MemBrain source files:  11759\n"
     ]
    }
   ],
   "source": [
    "WEBSITE_API = \"https://rest.uniprot.org/uniprotkb/\"\n",
    "source_data_dir = Path('./SourceData/MemBrain/')\n",
    "files = list(source_data_dir.glob('*.result'))\n",
    "print('Number of MemBrain source files: ', len(files))\n",
    "\n",
    "data = [] # Initialize a list to store row data before creating DataFrame\n",
    "\n",
    "for i, file_path in enumerate(files):\n",
    "    entry = file_path.stem\n",
    "    with file_path.open() as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    aa_sequence = lines[1]\n",
    "    prediction = lines[3]\n",
    "    AH_or_not = 'AH' if '1' in prediction else 'Non-AH'\n",
    "\n",
    "    try:\n",
    "        url = f\"{WEBSITE_API}/search?query=(accession:{entry})&fields=organism_name,gene_primary,protein_name,cc_subcellular_location\"\n",
    "        r = get_url(url)\n",
    "        result = r.json()['results'][0]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {entry}: {e}\")\n",
    "        continue  # Skip to the next file\n",
    "\n",
    "    # Initialize with default values\n",
    "    organism_name = gene_name = protein_name = subcell_loc = 'Unknown'\n",
    "    \n",
    "    # Attempt to extract data, with fallbacks in case of missing fields\n",
    "    organism_name = result.get('organism', {}).get('scientificName', organism_name)\n",
    "    if result.get('genes'):\n",
    "        gene_name = result['genes'][0].get('geneName', {}).get('value', gene_name)\n",
    "    if result.get('proteinDescription', {}).get('recommendedName'):\n",
    "        protein_name = result['proteinDescription']['recommendedName'].get('fullName', {}).get('value', protein_name)\n",
    "    subcell_locs = [loc['location']['value'] for loc in result.get('comments', [{}])[0].get('subcellularLocations', [])]\n",
    "    subcell_loc = ', '.join(subcell_locs) if subcell_locs else subcell_loc\n",
    "\n",
    "    data.append({\n",
    "        'Entry_original': entry,\n",
    "        'Organism': organism_name,\n",
    "        'Gene_name': gene_name,\n",
    "        'Protein_name': protein_name,\n",
    "        'AH_or_Not': AH_or_not,\n",
    "        'AA_sequence': aa_sequence.strip(),\n",
    "        'Prediction': prediction.strip(),\n",
    "        'SubCell_Uniprot': subcell_loc\n",
    "    })\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(i, entry, organism_name, protein_name)\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e71b82b1-f3f3-4fd8-9d11-1f1f3965a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df.to_csv('./IntermediateProducts/Results_step_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf66b9-aeef-4c64-a81c-5526ac8e9d49",
   "metadata": {},
   "source": [
    "# Step 2: Find metazoan proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d92eb5d-ade6-4046-8f49-52e72fb2ca4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './IntermediateProducts/Results_step_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the df from step 1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./IntermediateProducts/Results_step_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './IntermediateProducts/Results_step_1.csv'"
     ]
    }
   ],
   "source": [
    "# Import the df from step 1\n",
    "df = pd.read_csv('./IntermediateProducts/Results_step_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839c6659-60c3-4876-8a0d-0bab3b938900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of organism species in the data is  1521\n"
     ]
    }
   ],
   "source": [
    "# create organism list\n",
    "organism_list = df['Organism'].unique().tolist()\n",
    "print('Number of organism species in the data is ', len(organism_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b474cf-f79b-4b8b-8e21-f24bbf8a8616",
   "metadata": {},
   "source": [
    "#### Identify metazoan from the 1521 organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc584f3d-a72d-40ff-9ce1-fc7d72451d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Arabidopsis thaliana ['cellular organisms', 'Eukaryota']\n",
      "5 Homo sapiens ['cellular organisms', 'Eukaryota']\n"
     ]
    }
   ],
   "source": [
    "WEBSITE_API = 'https://rest.uniprot.org/taxonomy/'\n",
    "\n",
    "# a list for storage\n",
    "lineage_list = list()\n",
    "\n",
    "# regex for extracing organism name WITHOUT items in parenthesis\n",
    "regex = re.compile(r'([^()]+)(\\(.+\\))?')\n",
    "\n",
    "# scan organism list and get lineage from Uniprot Taxonomy\n",
    "for i, organism in enumerate(organism_list[:10]):\n",
    "    # extract organism name WITHOUT items in parenthesis such as strain name\n",
    "    mo = regex.search(organism)\n",
    "    if mo:\n",
    "        organism = mo.group(1).strip()\n",
    "    else:\n",
    "        lineage_list.append('Unknown')\n",
    "        continue\n",
    "        \n",
    "    # get response that contains lineage\n",
    "    try:\n",
    "        r = get_url(f'{WEBSITE_API}/search?query=(scientific:\"{organism}\")&fields=lineage')\n",
    "        result = r.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {entry}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # extract lineage from the result\n",
    "    # Attempt to extract lineage information from the response\n",
    "    try:\n",
    "        lineage = [l['scientificName'] for l in result['results'][0]['lineage']]\n",
    "        lineage_full = ', '.join(lineage) if lineage else 'NotFound'\n",
    "    except (KeyError, IndexError):\n",
    "        lineage_full = 'NotFound'  # In case the result structure is unexpected or empty\n",
    "        \n",
    "    # add to the found lineage to the list\n",
    "    lineage_list.append(lineage_full)\n",
    "    \n",
    "    # log every 100 showing the two highest levels of the lineage (e.g. Bacteria < Cellular organisms)\n",
    "    if i % 5 == 0: print(i, organism, lineage[:2])\n",
    "    \n",
    "    # take a break, go next\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53082a3a-e6cb-46bb-8455-7f25d8a8b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe for organisms\n",
    "df_org = pd.DataFrame(organism_list[:10], columns=['Organism'])\n",
    "df_org['Lineage'] = lineage_list\n",
    "\n",
    "# export just in case\n",
    "df_org.to_csv('./IntermediateProducts/Organisms_and_Lineage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "58e3da4a-908e-4f2a-8097-a51124e15659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of eukaryotic species is  431\n",
      "Number of bacteria species is  732\n",
      "Number of archea species is  61\n",
      "Number of virus species is  281\n",
      "Number of species not found in database is  16\n"
     ]
    }
   ],
   "source": [
    "# Just curious: How many are eukaryotes, bacteria, archea, and virus?\n",
    "n_eukaryote = len(df_org[df_org['Lineage'].str.contains('Eukaryot')])\n",
    "n_bacteria = len(df_org[df_org['Lineage'].str.contains('Bacteria')])\n",
    "n_archaea = len(df_org[df_org['Lineage'].str.contains('Archaea')])\n",
    "n_virus = len(df_org[df_org['Lineage'].str.contains('Virus')])\n",
    "n_notFound = len(df_org) - np.sum([n_eukaryote, n_bacteria, n_archaea, n_virus])\n",
    "print('Number of eukaryotic species is ', n_eukaryote)\n",
    "print('Number of bacteria species is ', n_bacteria)\n",
    "print('Number of archea species is ', n_archaea)\n",
    "print('Number of virus species is ', n_virus)\n",
    "print('Number of species not found in database is ', n_notFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "36384b7d-82f9-4aa6-abd5-f9b238990792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metazoan species is  122\n"
     ]
    }
   ],
   "source": [
    "# Select metazoans\n",
    "df_org_metazoa = df_org[df_org['Lineage'].str.contains('Metazoa')]\n",
    "print('Number of metazoan species is ', len(df_org_metazoa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a966d8f6-2201-4adb-93c6-eff449830e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_org_metazoa with the main df\n",
    "# by doing so, genes from metazoans are sorted\n",
    "df_metazoanGenes = df.merge(df_org_metazoa, how='inner', on='Organism')\n",
    "print('Number of metazoan proteins: ', len(df_metazoanGenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0217de85-b539-4c77-9918-74fffda13cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Lineage column\n",
    "df_metazoanGenes = df_metazoanGenes.drop(['Lineage'], axis=1)\n",
    "\n",
    "# export\n",
    "df_metazoanGenes.to_csv('./IntermediateProducts/Results_step_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac27aab-5c8d-47c9-968e-cbbe0d579bff",
   "metadata": {},
   "source": [
    "# Step 3: Convert non-human entries to human ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f17ea124-e113-44ac-812b-3cd35e2c7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import df from step 3\n",
    "df_metazoanGenes = pd.read_csv('./IntermediateProducts/Results_step_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ef07dee-ff74-47a6-a80f-14e5b77d4f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WEBSITE_API = \"https://rest.uniprot.org/uniprotkb/\"\n",
    "organism_id_list = {'Homo sapiens': '9606', 'Mus musculus': '10090'}\n",
    "\n",
    "converted_id_list = list() # For final output\n",
    "\n",
    "# Organism of interest either human or mouse\n",
    "organism_id = organism_id_list['Homo sapiens']\n",
    "\n",
    "# Counting how many genes were not found\n",
    "reused = similar_but_differ = not_found = 0\n",
    "\n",
    "# scan entries in the dataframe\n",
    "for i in range(len(df_metazoanGenes)):\n",
    "    if df_metazoanGenes.iloc[i, 1] == organism: # judge if the entry comes from human or mouse\n",
    "        entry_converted = df_metazoanGenes.iloc[i, 0] # reuse the original gene name\n",
    "        reused += 1\n",
    "    else: # obtain the human or mouse entry from uniprot\n",
    "        gene = df_metazoanGenes.iloc[i, 2]\n",
    "        try:\n",
    "            response = get_url(f'{WEBSITE_API}/search?query=gene:{gene}+AND+organism_id:{organism_id}+AND+reviewed:true&fields=accession,gene_names')\n",
    "            result = response.json().get('results', '')[0]\n",
    "\n",
    "            ## get human or mouse entry\n",
    "            entry_converted = result.get('primaryAccession', 'Not_found')\n",
    "            ## Check if the obtained entry points to the same gene\n",
    "            gene_obtained = result['genes'][0]['geneName']['value'].lower()\n",
    "            if gene.lower() != gene_obtained:\n",
    "                entry_converted = 'Not_found'\n",
    "                similar_but_differ += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error for gene name {gene} in row {i}: {e}\")\n",
    "            entry_converted = 'Not_found'\n",
    "            not_found += 1\n",
    "\n",
    "        # take a break\n",
    "        sleep(1)\n",
    "\n",
    "    # add to the final output list\n",
    "    converted_id_list.append(entry_converted)\n",
    "\n",
    "    # log every 100\n",
    "    if i % 100 == 0: print(i, gene, entry_converted)\n",
    "    \n",
    "# Add the result to Entry_Hs column\n",
    "df_metazoanGenes['Entry_Hs'] = converted_id_list\n",
    "\n",
    "print('Total number of genes that got converted to Hs: ', len(df_metazoanGenes) - reused - similar_but_differ - not_found)\n",
    "print('Number of genes for which similar gene name was found in Hs: ', similar_but_differ)\n",
    "print('Number of genes for which Hs homolog was not found: ', not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8650760-274d-45f0-8dac-cb431a510d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df_metazoanGenes.to_csv('./IntermediateProducts/Results_step_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
